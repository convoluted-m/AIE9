{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Agent Loop: Building Production Agents with LangChain 1.0\n",
    "\n",
    "In this notebook, we'll explore the foundational concepts of AI agents and learn how to build production-grade agents using LangChain's new `create_agent` abstraction with middleware support.\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand what an \"agent\" is and how the agent loop works\n",
    "- Learn the core constructs of LangChain (Runnables, LCEL)\n",
    "- Master the `create_agent` function and middleware system\n",
    "- Build an agentic RAG application using Qdrant\n",
    "\n",
    "## Table of Contents:\n",
    "\n",
    "- **Breakout Room #1:** Introduction to LangChain, LangSmith, and `create_agent`\n",
    "  - Task 1: Dependencies\n",
    "  - Task 2: Environment Variables\n",
    "  - Task 3: LangChain Core Concepts (Runnables & LCEL)\n",
    "  - Task 4: Understanding the Agent Loop\n",
    "  - Task 5: Building Your First Agent with `create_agent()`\n",
    "  - Question #1 & Question #2\n",
    "  - Activity #1: Create a Custom Tool\n",
    "\n",
    "- **Breakout Room #2:** Middleware - Agentic RAG with Qdrant\n",
    "  - Task 6: Loading & Chunking Documents\n",
    "  - Task 7: Setting up Qdrant Vector Database\n",
    "  - Task 8: Creating a RAG Tool\n",
    "  - Task 9: Introduction to Middleware\n",
    "  - Task 10: Building Agentic RAG with Middleware\n",
    "  - Question #3 & Question #4\n",
    "  - Activity #2: Enhance the Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ù Breakout Room #1\n",
    "## Introduction to LangChain, LangSmith, and `create_agent`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Dependencies\n",
    "\n",
    "First, let's ensure we have all the required packages installed. We'll be using:\n",
    "\n",
    "- **LangChain 1.0+**: The core framework with the new `create_agent` API\n",
    "- **LangChain-OpenAI**: OpenAI model integrations\n",
    "- **LangSmith**: Observability and tracing\n",
    "- **Qdrant**: Vector database for RAG\n",
    "- **tiktoken**: Token counting for text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to install dependencies (if not using uv sync)\n",
    "# !pip install langchain>=1.0.0 langchain-openai langsmith langgraph qdrant-client langchain-qdrant tiktoken nest-asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports we'll use throughout the notebook\n",
    "import os\n",
    "import getpass\n",
    "from uuid import uuid4\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()  # Required for async operations in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Environment Variables\n",
    "\n",
    "We need to set up our API keys for:\n",
    "1. **OpenAI** - For the GPT-5 model\n",
    "2. **LangSmith** - For tracing and observability (optional but recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set OpenAI API Key\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"OpenAI API Key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Set up LangSmith for tracing\n",
    "# This provides powerful debugging and observability for your agents\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIE9 - The Agent Loop - {uuid4().hex[0:8]}\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass(\"LangSmith API Key (press Enter to skip): \") or \"\"\n",
    "\n",
    "if not os.environ[\"LANGCHAIN_API_KEY\"]:\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"false\"\n",
    "    print(\"LangSmith tracing disabled\")\n",
    "else:\n",
    "    print(f\"LangSmith tracing enabled. Project: {os.environ['LANGCHAIN_PROJECT']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: LangChain Core Concepts\n",
    "\n",
    "Before diving into agents, let's understand the fundamental building blocks of LangChain.\n",
    "\n",
    "### What is a Runnable?\n",
    "\n",
    "A **Runnable** is the core abstraction in LangChain - think of it as a standardized component that:\n",
    "- Takes an input\n",
    "- Performs some operation\n",
    "- Returns an output\n",
    "\n",
    "Every component in LangChain (models, prompts, retrievers, parsers) is a Runnable, which means they all share the same interface:\n",
    "\n",
    "```python\n",
    "result = runnable.invoke(input)           # Single input\n",
    "results = runnable.batch([input1, input2]) # Multiple inputs\n",
    "for chunk in runnable.stream(input):       # Streaming\n",
    "    print(chunk)\n",
    "```\n",
    "\n",
    "### What is LCEL (LangChain Expression Language)?\n",
    "\n",
    "**LCEL** allows you to chain Runnables together using the `|` (pipe) operator:\n",
    "\n",
    "```python\n",
    "chain = prompt | model | output_parser\n",
    "result = chain.invoke({\"query\": \"Hello!\"})\n",
    "```\n",
    "\n",
    "This is similar to Unix pipes - the output of one component becomes the input to the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see LCEL in action with a simple example\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create our components (each is a Runnable)\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant that speaks like a pirate.\"),\n",
    "    (\"human\", \"{question}\")\n",
    "])\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-5\", temperature=0.7)\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Chain them together with LCEL\n",
    "pirate_chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the chain\n",
    "response = pirate_chain.invoke({\"question\": \"What is the capital of France?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Understanding the Agent Loop\n",
    "\n",
    "### What is an Agent?\n",
    "\n",
    "An **agent** is a system that uses an LLM to decide what actions to take. Unlike a simple chain that follows a fixed sequence, an agent can:\n",
    "\n",
    "1. **Reason** about what to do next\n",
    "2. **Take actions** by calling tools\n",
    "3. **Observe** the results\n",
    "4. **Iterate** until the task is complete\n",
    "\n",
    "### The Agent Loop\n",
    "\n",
    "The core of every agent is the **agent loop**:\n",
    "\n",
    "```\n",
    "                          AGENT LOOP                         \n",
    "                                                             \n",
    "      +----------+     +----------+     +----------+         \n",
    "      |  Model   | --> |   Tool   | --> |  Model   | --> ... \n",
    "      |   Call   |     |   Call   |     |   Call   |         \n",
    "      +----------+     +----------+     +----------+         \n",
    "           |                                  |              \n",
    "           v                                  v              \n",
    "      \"Use search\"                   \"Here's the answer\"     \n",
    "```\n",
    "\n",
    "1. **Model Call**: The LLM receives the current state and decides whether to:\n",
    "   - Call a tool (continue the loop)\n",
    "   - Return a final answer (exit the loop)\n",
    "\n",
    "2. **Tool Call**: If the model decides to use a tool, the tool is executed and its output is added to the conversation\n",
    "\n",
    "3. **Repeat**: The loop continues until the model decides it has enough information to answer\n",
    "\n",
    "### Why `create_agent`?\n",
    "\n",
    "LangChain 1.0 introduced `create_agent` as the new standard way to build agents. It provides:\n",
    "\n",
    "- **Simplified API**: One function to create production-ready agents\n",
    "- **Middleware Support**: Hook into any point in the agent loop\n",
    "- **Built on LangGraph**: Uses the battle-tested LangGraph runtime under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Building Your First Agent with `create_agent()`\n",
    "\n",
    "Let's build a simple agent that can perform calculations and tell the time.\n",
    "\n",
    "### Step 1: Define Tools\n",
    "\n",
    "Tools are functions that the agent can call. We use the `@tool` decorator to create them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def calculate(expression: str) -> str:\n",
    "    \"\"\"Evaluate a mathematical expression. Use this for any math calculations.\n",
    "    \n",
    "    Args:\n",
    "        expression: A mathematical expression to evaluate (e.g., '2 + 2', '10 * 5')\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Using eval with restricted globals for safety\n",
    "        result = eval(expression, {\"__builtins__\": {}}, {})\n",
    "        return f\"The result of {expression} is {result}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating expression: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time. Use this when the user asks about the current time or date.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return f\"The current date and time is: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "\n",
    "# Create our tool belt\n",
    "tools = [calculate, get_current_time]\n",
    "\n",
    "print(\"Tools created:\")\n",
    "for t in tools:\n",
    "    print(f\"  - {t.name}: {t.description[:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the Agent\n",
    "\n",
    "Now we use `create_agent` to build our agent. The function takes:\n",
    "- `model`: The LLM to use (can be a string like `\"gpt-5\"` or a model instance)\n",
    "- `tools`: List of tools the agent can use\n",
    "- `prompt`: Optional system prompt to customize behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Create our first agent\n",
    "simple_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can perform calculations and tell the time. Always explain your reasoning.\"\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(simple_agent)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Run the Agent\n",
    "\n",
    "The agent is a Runnable, so we can invoke it like any other LangChain component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent with a simple calculation\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 25 * 48?\"}]}\n",
    ")\n",
    "\n",
    "# Print the final response\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a multi-step question that requires multiple tool calls\n",
    "response = simple_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What time is it, and what is 100 divided by the current hour?\"}]}\n",
    ")\n",
    "\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the full conversation to understand the agent loop\n",
    "print(\"Full Agent Conversation:\")\n",
    "print(\"=\" * 50)\n",
    "for msg in response[\"messages\"]:\n",
    "    role = msg.type if hasattr(msg, 'type') else 'unknown'\n",
    "    content = msg.content if hasattr(msg, 'content') else str(msg)\n",
    "    print(f\"\\n[{role.upper()}]\")\n",
    "    print(content[:500] if len(str(content)) > 500 else content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Agent Responses\n",
    "\n",
    "For better UX, we can stream the agent's responses as they're generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream the agent's response\n",
    "print(\"Streaming Agent Response:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for chunk in simple_agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Calculate 15% of 250\"}]},\n",
    "    stream_mode=\"updates\"\n",
    "):\n",
    "    for node, values in chunk.items():\n",
    "        print(f\"\\n[Node: {node}]\")\n",
    "        if \"messages\" in values:\n",
    "            for msg in values[\"messages\"]:\n",
    "                if hasattr(msg, 'content') and msg.content:\n",
    "                    print(msg.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #1:\n",
    "\n",
    "In the agent loop, what determines whether the agent continues to call tools or returns a final answer to the user? How does `create_agent` handle this decision internally?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "The agent runs until it achieves its goal (it's like a 'while' loop). We can use middleware hooks to set a limit of model calls if we want more control over it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #2:\n",
    "\n",
    "Looking at the `calculate` and `get_current_time` tools we created, why is the **docstring** so important for each tool? How does the agent use this information when deciding which tool to call?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "The docstring is read by the model when deciding which tool to use and how."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #1: Create a Custom Tool\n",
    "\n",
    "Create your own custom tool and add it to the agent! \n",
    "\n",
    "Ideas:\n",
    "- A tool that converts temperatures between Celsius and Fahrenheit\n",
    "- A tool that generates a random number within a range\n",
    "- A tool that counts words in a given text\n",
    "\n",
    "Requirements:\n",
    "1. Use the `@tool` decorator\n",
    "2. Include a clear docstring (this is what the agent sees!)\n",
    "3. Add it to the agent and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent created successfully!\n",
      "Type: <class 'langgraph.graph.state.CompiledStateGraph'>\n"
     ]
    }
   ],
   "source": [
    "# Create a word counter tool\n",
    "@tool\n",
    "def word_counter(text: str) -> str:\n",
    "    \"\"\"Counts words in a piece of text. Takes a string and returns the number of words in it.\n",
    "\n",
    "    Args:\n",
    "        text: A string to count the words\n",
    "    \"\"\"\n",
    "    try:\n",
    "        result = len(text.split())\n",
    "        return f\"The text has {result} words.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error evaluating text: {e}\"\n",
    "\n",
    "# Add word_counter to the tools list\n",
    "tools =[calculate, get_current_time, word_counter]\n",
    "\n",
    "# Create a new agent with the word counter tool\n",
    "new_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=tools,\n",
    "    system_prompt=\"You are a helpful assistant that can count words in a piece of text.\"\n",
    ")\n",
    "\n",
    "print(\"Agent created successfully!\")\n",
    "print(f\"Type: {type(new_agent)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Response:\n",
      "The text has 36 words.\n"
     ]
    }
   ],
   "source": [
    "# Test word counter tool on an excerpt from an Irish folk song\n",
    "response = new_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Low lie the Fields of Athenry. Where once we watched the small free birds fly. Our love was on the wing. We had dreams and songs to sing. It's so lonely 'round the Fields of Athenry.\"}]}\n",
    ")\n",
    "print(\"Agent Response:\")\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# ü§ù Breakout Room #2\n",
    "## Middleware - Agentic RAG with Qdrant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand the basics of agents, let's build something more powerful: an **Agentic RAG** system.\n",
    "\n",
    "Traditional RAG follows a fixed pattern: retrieve ‚Üí generate. But **Agentic RAG** gives the agent control over when and how to retrieve information, making it more flexible and intelligent.\n",
    "\n",
    "We'll also introduce **middleware** - hooks that let us customize the agent's behavior at every step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Loading & Chunking Documents\n",
    "\n",
    "We'll use the same Health & Wellness Guide from Session 2 to maintain continuity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the document using our aimakerspace utilities\n",
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "\n",
    "# Load the document (Health & Wellness Guide)\n",
    "text_loader = TextFileLoader(\"data/HealthWellnessGuide.txt\")\n",
    "documents = text_loader.load_documents()\n",
    "\n",
    "print(f\"Loaded {len(documents)} document(s)\")\n",
    "print(f\"Total characters: {sum(len(doc) for doc in documents):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents into chunks\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_texts(documents)\n",
    "\n",
    "print(f\"Split into {len(chunks)} chunks\")\n",
    "print(f\"\\nSample chunk:\")\n",
    "print(\"-\" * 50)\n",
    "print(chunks[0][:300] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 7: Setting up Qdrant Vector Database\n",
    "\n",
    "Qdrant is a production-ready vector database. We'll use an in-memory instance for development, but the same code works with a hosted Qdrant instance.\n",
    "\n",
    "Key concepts:\n",
    "- **Collection**: A namespace for storing vectors (like a table in SQL)\n",
    "- **Points**: Individual vectors with optional payloads (metadata)\n",
    "- **Distance**: How similarity is measured (we'll use cosine similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed document chunks with OpenAI embeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_qdrant import QdrantVectorStore\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.http.models import Distance, VectorParams\n",
    "\n",
    "# Initialize the embedding model\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "# Get embedding dimension\n",
    "sample_embedding = embedding_model.embed_query(\"test\")\n",
    "embedding_dim = len(sample_embedding)\n",
    "print(f\"Embedding dimension: {embedding_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store embeddings in Qdrant vector database\n",
    "# Create Qdrant client (in-memory for development)\n",
    "qdrant_client = QdrantClient(\":memory:\")\n",
    "\n",
    "# Create a collection for our wellness documents\n",
    "collection_name = \"wellness_knowledge_base\"\n",
    "\n",
    "qdrant_client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=embedding_dim,\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"Created collection: {collection_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vector store and add documents\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "# Convert chunks to LangChain Document objects\n",
    "langchain_docs = [Document(page_content=chunk) for chunk in chunks]\n",
    "\n",
    "# Create vector store\n",
    "vector_store = QdrantVectorStore(\n",
    "    client=qdrant_client,\n",
    "    collection_name=collection_name,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "# Add documents to the vector store\n",
    "vector_store.add_documents(langchain_docs)\n",
    "\n",
    "print(f\"Added {len(langchain_docs)} documents to vector store\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create aretriever\n",
    "retriever = vector_store.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "# test the retriever (that it pulls relevant chunks)\n",
    "test_results = retriever.invoke(\"How can I improve my sleep?\")\n",
    "\n",
    "print(\"Retrieved documents:\")\n",
    "for i, doc in enumerate(test_results, 1):\n",
    "    print(f\"\\n--- Document {i} ---\")\n",
    "    print(doc.page_content[:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 8: Creating a RAG Tool\n",
    "\n",
    "Now we'll wrap our retriever as a tool that the agent can use. This is the key to **Agentic RAG** - the agent decides when to retrieve information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap the retriever as a tool so that the agent can use it for domain knowledge\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def search_wellness_knowledge(query: str) -> str:\n",
    "    \"\"\"Search the wellness knowledge base for information about health, fitness, nutrition, sleep, and mental wellness.\n",
    "    \n",
    "    Use this tool when the user asks questions about:\n",
    "    - Physical health and fitness\n",
    "    - Nutrition and diet\n",
    "    - Sleep and rest\n",
    "    - Mental health and stress management\n",
    "    - General wellness tips\n",
    "    \n",
    "    Args:\n",
    "        query: The search query to find relevant wellness information\n",
    "    \"\"\"\n",
    "   \n",
    "    # invoke the retriever\n",
    "    results = retriever.invoke(query)\n",
    "    \n",
    "    if not results:\n",
    "        return \"No relevant information found in the wellness knowledge base.\"\n",
    "    \n",
    "    # Format the results\n",
    "    formatted_results = []\n",
    "    for i, doc in enumerate(results, 1):\n",
    "        formatted_results.append(f\"[Source {i}]:\\n{doc.page_content}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(formatted_results)\n",
    "\n",
    "print(f\"Tool created: {search_wellness_knowledge.name}\")\n",
    "print(f\"Description: {search_wellness_knowledge.description[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 9: Introduction to Middleware\n",
    "\n",
    "**Middleware** in LangChain 1.0 allows you to hook into the agent loop at various points:\n",
    "\n",
    "```\n",
    "                       MIDDLEWARE HOOKS                 \n",
    "                                                        \n",
    "   +--------------+                    +--------------+ \n",
    "   | before_model | --> MODEL CALL --> | after_model  | \n",
    "   +--------------+                    +--------------+ \n",
    "                                                        \n",
    "   +-------------------+                                \n",
    "   | wrap_model_call   |  (intercept and modify calls)  \n",
    "   +-------------------+                                \n",
    "```\n",
    "\n",
    "Common use cases:\n",
    "- **Logging**: Track what the agent is doing\n",
    "- **Guardrails**: Filter or modify inputs/outputs\n",
    "- **Rate limiting**: Control API usage\n",
    "- **Human-in-the-loop**: Pause for human approval\n",
    "\n",
    "LangChain provides middleware through **decorator functions** that hook into specific points in the agent loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents.middleware import before_model, after_model\n",
    "\n",
    "# Track how many model calls we've made\n",
    "model_call_count = 0\n",
    "\n",
    "@before_model\n",
    "def log_before_model(state, runtime):\n",
    "    \"\"\"Called before each model invocation.\n",
    "        Logs the number of messages in the state and the model call count.\n",
    "    \"\"\"\n",
    "    global model_call_count\n",
    "    model_call_count += 1\n",
    "    message_count = len(state.get(\"messages\", []))\n",
    "    print(f\"[LOG] Model call #{model_call_count} - Messages in state: {message_count}\")\n",
    "    return None  # Return None to continue without modification\n",
    "\n",
    "@after_model\n",
    "def log_after_model(state, runtime):\n",
    "    \"\"\"Called after each model invocation.\n",
    "    Logs the last message in the state and whether it has tool calls.\n",
    "    \"\"\"\n",
    "    last_message = state.get(\"messages\", [])[-1] if state.get(\"messages\") else None\n",
    "    if last_message:\n",
    "        has_tool_calls = hasattr(last_message, 'tool_calls') and last_message.tool_calls\n",
    "        print(f\"[LOG] After model - Tool calls requested: {has_tool_calls}\")\n",
    "    return None\n",
    "\n",
    "print(\"Logging middleware created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the built-in ModelCallLimitMiddleware to prevent runaway agents\n",
    "from langchain.agents.middleware import ModelCallLimitMiddleware\n",
    "\n",
    "# This middleware will stop the agent after 10 model calls per thread\n",
    "call_limiter = ModelCallLimitMiddleware(\n",
    "    thread_limit=10,  # Max calls per conversation thread\n",
    "    run_limit=5,      # Max calls per single run\n",
    "    exit_behavior=\"end\"  # What to do when limit is reached\n",
    ")\n",
    "\n",
    "print(\"Call limit middleware created!\")\n",
    "print(f\"  - Thread limit: {call_limiter.thread_limit}\")\n",
    "print(f\"  - Run limit: {call_limiter.run_limit}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 10: Building Agentic RAG with Middleware\n",
    "\n",
    "Now let's put it all together: an agentic RAG system with middleware support!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "# Reset the call counter\n",
    "model_call_count = 0\n",
    "\n",
    "# Define our tools - include the RAG tool and the calculator from earlier\n",
    "rag_tools = [\n",
    "    search_wellness_knowledge,\n",
    "    calculate,\n",
    "    get_current_time\n",
    "]\n",
    "\n",
    "# Create the agentic RAG system with middleware\n",
    "wellness_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=rag_tools,\n",
    "    system_prompt=\"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. Always search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\",\n",
    "    middleware=[\n",
    "        log_before_model,\n",
    "        log_after_model,\n",
    "        call_limiter\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Wellness Agent created with middleware!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the wellness agent\n",
    "print(\"Testing Wellness Agent\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What are some tips for better sleep?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a more complex query\n",
    "print(\"Testing with complex query\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I'm feeling stressed and having trouble sleeping. What should I do, and if I sleep 6 hours a night for a week, how many total hours is that?\"}]}\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the agent's ability to know when NOT to use RAG\n",
    "print(\"Testing agent decision-making (should NOT use RAG)\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "response = wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is 125 * 8?\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Agent\n",
    "\n",
    "The agent created by `create_agent` is built on LangGraph, so we can visualize its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the agent graph\n",
    "try:\n",
    "    from IPython.display import display, Image\n",
    "    display(Image(wellness_agent.get_graph().draw_mermaid_png()))\n",
    "except Exception as e:\n",
    "    print(f\"Could not display graph: {e}\")\n",
    "    print(\"\\nAgent structure:\")\n",
    "    print(wellness_agent.get_graph().draw_ascii())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚ùì Question #3:\n",
    "\n",
    "How does **Agentic RAG** differ from traditional RAG? What are the advantages and potential disadvantages of letting the agent decide when to retrieve information?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "Traditional RAG contains a fixed \"query ‚Üí retrieve‚Üí generate‚Äù logic while in agentic RAG, the agent controls when and how to retrieve information/ use  tools. Agentic RAG is flexible so it can solve problems \"creatively\", e.g. run the loop multiple times it if decides it doesn't have enough info to complete a task, use multiple tools in a loop, or even not retrieve info at all if not needed. However, if limits are not set (like we did here with middleware), agentic RAG can  result in higher number of calls and hence costs and potentially looping forever in order to achieve the goal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Question #4:\n",
    "\n",
    "Looking at the middleware examples (`log_before_model`, `log_after_model`, and `ModelCallLimitMiddleware`), describe a real-world scenario where middleware would be essential for a production agent. What specific middleware hooks would you use and why?\n",
    "\n",
    "##### ‚úÖ Answer:\n",
    "For example, in a customer service solution, I would use middleware for: 1) observability to track all the steps and help with debugging and evaluation; perhaps to track metrics too like resolution time (before and after model call, and before and after tool execution); 2) guardrails to ensure no irrelevant/harmful input is being fed into the loop if out of scope/toxic (before model call) and that the output fits the established criteria of relevance, safety, etc. (after model call); 3) PII redaction of sensitive customer data (before model call) 4) routing to appropriate tools, e.g. cheaper models or ML classifiers for simple queries and LLMs for more complex/contextual queries and fallbacks; 5)the rate limit to control the costs (before tool execution) 6) human in the loop for, e.g. account cancellations, high value transactions, multiple failed attempt escalations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üèóÔ∏è Activity #2: Enhance the Agentic RAG System\n",
    "\n",
    "Now it's your turn! Enhance the wellness agent by implementing ONE of the following:\n",
    "\n",
    "### Option A: Add a New Tool\n",
    "Create a new tool that the agent can use. Ideas:\n",
    "- A tool that calculates BMI given height and weight\n",
    "- A tool that estimates daily calorie needs\n",
    "- A tool that creates a simple workout plan\n",
    "\n",
    "### Option B: Create Custom Middleware\n",
    "Build middleware that adds new functionality:\n",
    "- Middleware that tracks which tools are used most frequently\n",
    "- Middleware that adds a friendly greeting to responses\n",
    "- Middleware that enforces a response length limit\n",
    "\n",
    "### Option C: Improve the RAG Tool\n",
    "Enhance the retrieval tool:\n",
    "- Add metadata filtering\n",
    "- Implement reranking of results\n",
    "- Add source citations with relevance scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decided to add a tool to calculate calorie needs. For this use case,I would also consider other tools like: tracking whether my calorie counter tool is used, where in the loop and how often for debugging and optimization; guardrails for  sensitive questions that should intercept red flag queries about anorexia or self-harm before the model call, as well as medical disclaimer after the model call to inject into final response; call tracker to limit how often and how many tools the model uses, perhaps some use is not justified and costly; personalisation if that was embedded within an app where a user could log their details and preferences (could then inject those to augment the prompt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a tool to caclculate calorie needs\n",
    "\n",
    "# Create the tool\n",
    "@tool\n",
    "def calculate_calories(age: int, weight: int, height: int, gender: str, activity_level: str) -> str:\n",
    "    \"\"\"\n",
    "    Calculate the number of calories a person needs based on their age, weight, height,  gender and activity level.\n",
    "    \n",
    "    Args:\n",
    "        age: The age of the person, int\n",
    "        weight: The weight of the person in kilograms, int\n",
    "        height: The height of the person in centimeters, int\n",
    "        gender: The gender of the person from options: \"male\", \"female\", str\n",
    "        activity_level: The activity level of the person from options: \"sedentary\", \"lightly active\", \"moderately active\", \"very active\", \"super active\" str\n",
    "    \"\"\"\n",
    "    gender_normalised = gender.lower()\n",
    "    if gender_normalised == \"male\":\n",
    "        bmr = 10 * weight + 6.25 * height - 5 * age + 5\n",
    "    else:\n",
    "        if gender_normalised == \"female\":\n",
    "            bmr = 10 * weight + 6.25 * height - 5 * age - 161\n",
    "        else:\n",
    "            return \"Please specify gender as either 'male' or 'female'.\"\n",
    "    activity_level_normalised = activity_level.lower()              \n",
    "    if activity_level_normalised == \"sedentary\":\n",
    "        daily_calories = bmr * 1.2\n",
    "    elif activity_level_normalised == \"lightly active\":\n",
    "        daily_calories = bmr * 1.375\n",
    "    elif activity_level_normalised == \"moderately active\":\n",
    "        daily_calories = bmr * 1.55\n",
    "    elif activity_level_normalised  == \"very active\":\n",
    "        daily_calories = bmr * 1.725\n",
    "    elif activity_level_normalised == \"super active\":\n",
    "        daily_calories = bmr * 1.9\n",
    "    else:\n",
    "        return \"Please specify activity level as either 'sedentary', 'lightly active', 'moderately active', 'very active', or 'super active'\"   \n",
    "        \n",
    "    return f\"The person's BMR is {bmr} and the number of calories the person needs to eat is {daily_calories}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "activity_level: The activity level of the person from options: \"sedentary\", \"lightly active\", \"moderately active\", \"very active\", str\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the enhanced agent\n",
    "model_call_count = 0\n",
    "\n",
    "rag_tools = [\n",
    "    search_wellness_knowledge,\n",
    "    calculate,\n",
    "    get_current_time,\n",
    "    calculate_calories\n",
    "]\n",
    "\n",
    "enhanced_wellness_agent = create_agent(\n",
    "    model=\"gpt-5\",\n",
    "    tools=rag_tools,\n",
    "    system_prompt=\"\"\"You are a helpful wellness assistant with access to a comprehensive health and wellness knowledge base.\n",
    "\n",
    "Your role is to:\n",
    "1. Answer questions about health, fitness, nutrition, sleep, and mental wellness\n",
    "2. Always search the knowledge base when the user asks wellness-related questions\n",
    "3. Provide accurate, helpful information based on the retrieved context\n",
    "4. Be supportive and encouraging in your responses\n",
    "5. If you cannot find relevant information, say so honestly\n",
    "\n",
    "Remember: Always cite information from the knowledge base when applicable.\"\"\",\n",
    "    middleware=[\n",
    "        log_before_model,\n",
    "        log_after_model,\n",
    "        call_limiter\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Model call #1 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'calculate_calories', 'args': {'age': 30, 'weight': 60, 'height': 160, 'gender': 'female', 'activity_level': 'moderately active'}, 'id': 'call_3iwYf3QNSDl0keC8kaBl790e', 'type': 'tool_call'}, {'name': 'search_wellness_knowledge', 'args': {'query': \"daily calorie needs calculator Mifflin-St Jeor TDEE activity factors definitions 'moderately active' female 30 160 cm 60 kg\"}, 'id': 'call_efqefZYjLs6SmNgB3gZYkbC8', 'type': 'tool_call'}]\n",
      "[LOG] Model call #2 - Messages in state: 4\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Here‚Äôs an estimate based on the Mifflin‚ÄìSt Jeor equation and a ‚Äúmoderately active‚Äù lifestyle (about 3‚Äì5 days/week of moderate exercise):\n",
      "\n",
      "- Basal Metabolic Rate (BMR): ~1,289 kcal/day\n",
      "- Maintenance calories (TDEE): ~2,000 kcal/day\n",
      "\n",
      "If your goal changes:\n",
      "- Fat loss: ~1,500‚Äì1,700 kcal/day (300‚Äì500 kcal below maintenance)\n",
      "- Muscle gain: ~2,300‚Äì2,500 kcal/day (300‚Äì500 kcal above maintenance)\n",
      "\n",
      "Note: I couldn‚Äôt find a specific knowledge-base article to cite for this calculation; this estimate uses the widely accepted Mifflin‚ÄìSt Jeor formula with a moderate activity factor (~1.55). Track your weight and energy levels for 2‚Äì4 weeks and adjust by ~100‚Äì200 kcal/day if needed.\n",
      "\n",
      "Would you like me to tailor macros or a sample day of eating based on your goal?\n"
     ]
    }
   ],
   "source": [
    "# Test the enhanced agent \n",
    "response = enhanced_wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"How many calories do I need to eat? I'm a 30 year old female, 160 tall and weigh 60kg. I'm moderately active.\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Model call #3 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'safe calorie deficit for weight loss, recommended rate of weight loss per week, minimum calorie intake for men, sedentary activity definitions, TDEE and calorie deficit guidelines'}, 'id': 'call_LTA0X1RFMErAOfZMjM2a9tcK', 'type': 'tool_call'}, {'name': 'calculate_calories', 'args': {'age': 40, 'weight': 96, 'height': 170, 'gender': 'male', 'activity_level': 'sedentary'}, 'id': 'call_AqvnfrWLQqy6EgfdZRu4vRzu', 'type': 'tool_call'}]\n",
      "[LOG] Model call #4 - Messages in state: 4\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "Thanks for the details. Based on your stats and a sedentary activity level, your estimated maintenance is about 2,190 kcal/day (BMR ‚âà 1,828; from our calorie calculator).\n",
      "\n",
      "For steady weight loss:\n",
      "- Aim for roughly 1,700‚Äì1,850 kcal/day (about a 15‚Äì25% deficit). A simple starting point is ~1,800 kcal/day.\n",
      "- Expected pace: about 0.3‚Äì0.5 kg per week if you‚Äôre consistent.\n",
      "- Adjust by 100‚Äì200 kcal (up or down) after 2‚Äì3 weeks based on your average weekly weight change.\n",
      "\n",
      "Helpful tips:\n",
      "- Protein: target roughly 120‚Äì160 g/day to support fullness and muscle.\n",
      "- Fill half your plate with vegetables/fruit; include whole grains and healthy fats.\n",
      "- Track intake (app or food log) and weigh yourself 1‚Äì2x/week under similar conditions.\n",
      "- Light movement (e.g., 20‚Äì30 minutes walking most days) helps appetite, health, and allows a slightly higher calorie target.\n",
      "\n",
      "Would you like a sample 1,800-kcal day or a simple macro breakdown?\n"
     ]
    }
   ],
   "source": [
    "# Test 2\n",
    "response = enhanced_wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"How many calories do I need to eat to lose weight? I'm 40, male, 170cm, weigh about 96kg. I don't move much.\"}]}\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LOG] Model call #8 - Messages in state: 1\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'muscle gain nutrition guidelines calorie surplus how much to eat per day protein 1.6-2.2 g/kg evidence; women; BMI categories normal 18.5-24.9; creatine 3-5 g/day strength training sleep 7-9 hours; carbohydrate recommendations for hypertrophy'}, 'id': 'call_w3d1eb9axtLthzqi4o4m4Q7n', 'type': 'tool_call'}]\n",
      "[LOG] Model call #9 - Messages in state: 3\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'how many calories to gain muscle calorie surplus 250-500 kcal protein 1.6-2.2 g/kg per day resistance training women beginner muscle gain guidelines'}, 'id': 'call_wyj7jtg3KOWcK9wj6blzcW4f', 'type': 'tool_call'}]\n",
      "[LOG] Model call #10 - Messages in state: 5\n",
      "[LOG] After model - Tool calls requested: [{'name': 'search_wellness_knowledge', 'args': {'query': 'protein intake for muscle growth grams per kilogram recommendations 1.6-2.2 g/kg carbs per kg hypertrophy guidance wellness knowledge base'}, 'id': 'call_3AS23aHLZzpq6fJTrVLwUXvG', 'type': 'tool_call'}]\n",
      "[LOG] Model call #11 - Messages in state: 7\n",
      "[LOG] After model - Tool calls requested: [{'name': 'calculate', 'args': {'expression': '55 / (1.70 * 1.70)'}, 'id': 'call_sCvSDyVn79bhMmGPumwNNTnZ', 'type': 'tool_call'}]\n",
      "[LOG] Model call #12 - Messages in state: 9\n",
      "[LOG] After model - Tool calls requested: []\n",
      "\n",
      "==================================================\n",
      "FINAL RESPONSE:\n",
      "==================================================\n",
      "You‚Äôre not alone in feeling that way. For context, at 55 kg and 170 cm your BMI is about 19.0, which is within the healthy range‚Äîjust on the lean side. If your goal is to look and feel stronger, focusing on building muscle and gaining weight slowly is a great plan.\n",
      "\n",
      "How much to eat\n",
      "- Aim for a small daily calorie surplus above your maintenance (often around 250‚Äì400 kcal/day). This helps you gain mostly muscle rather than excess fat. Our knowledge base doesn‚Äôt list exact surplus numbers, but this is a commonly used, evidence-based range.\n",
      "- Protein is key for muscle repair and growth. A practical target many lifters use is about 1.6‚Äì2.2 g/kg body weight per day. For you, that‚Äôs roughly 90‚Äì120 g protein/day. The knowledge base covers the roles of macronutrients (protein for muscle repair, carbs for energy, fats for hormone production) even though it doesn‚Äôt specify gram targets [Source 3].\n",
      "- Carbs fuel training; include them around workouts. Healthy fats help you meet calories comfortably.\n",
      "\n",
      "Training and recovery (important for actually building muscle)\n",
      "- Use progressive overload in your strength training‚Äîgradually increase weights, reps, or sets over time [Source 2].\n",
      "- Prioritize sleep (most adults need 7‚Äì9 hours) to support recovery and muscle growth [Source 2].\n",
      "- Keep meals balanced with carbs, protein, and healthy fats [Source 3].\n",
      "\n",
      "Simple way to structure your day\n",
      "- 3 meals + 1‚Äì2 protein-rich snacks.\n",
      "- Include 20‚Äì40 g protein at each meal (eggs/Greek yogurt/tofu/chicken/beans), a good carb source (rice, oats, pasta, potatoes, fruit), veggies, and add fats (olive oil, avocado, nuts) to help hit calories.\n",
      "\n",
      "Want me to calculate a personalized daily calorie target? Share:\n",
      "- Age\n",
      "- Typical weekly activity level (sedentary, lightly active, moderately active, very active)\n",
      "- How many days per week you plan to do resistance training\n",
      "\n",
      "I can run the numbers and give you a starting calorie target plus a sample day of eating.\n"
     ]
    }
   ],
   "source": [
    "# Test 3 - more ambiguous query\n",
    "response = enhanced_wellness_agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"I wonder how much to eat a day to build muscles. I am quite thin and want to gain weight. I weigh like 55kg and I'm 170cm, that's not much for a tall woman is it?\"}]}\n",
    ")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"FINAL RESPONSE:\")\n",
    "print(\"=\" * 50)\n",
    "print(response[\"messages\"][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
